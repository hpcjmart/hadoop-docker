{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404051f9-d925-4157-a945-e3d693f7523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf3b273-5f92-4822-9233-54ce9ac317a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8617cfb0-8d0e-44e9-9a2b-5748c8fdde01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab625159-be6f-416d-8bab-a564e109e900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d89454-0ce2-4041-a042-6218349de221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE emp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85621044-e9e1-4270-8746-065f75614f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|      emp|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4f1ee1-d897-4a9f-8a09-6454079d0b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP DATABASE emp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beae49d1-c2b3-42ea-82b9-1bc8cc30baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|      src|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63a53ba-d337-4321-bce9-af4875e9b41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09b33b6f-efbe-4e21-8f88-b7973d46571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|      src|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e9f3d24-28ed-40a6-8557-a0f446111d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|key|  value|\n",
      "+---+-------+\n",
      "|238|val_238|\n",
      "| 86| val_86|\n",
      "|311|val_311|\n",
      "| 27| val_27|\n",
      "|165|val_165|\n",
      "|409|val_409|\n",
      "|255|val_255|\n",
      "|278|val_278|\n",
      "| 98| val_98|\n",
      "|484|val_484|\n",
      "|265|val_265|\n",
      "|193|val_193|\n",
      "|401|val_401|\n",
      "|150|val_150|\n",
      "|273|val_273|\n",
      "|224|val_224|\n",
      "|369|val_369|\n",
      "| 66| val_66|\n",
      "|128|val_128|\n",
      "|213|val_213|\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from src\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f0e43-3055-4cc6-9968-7a305db5dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://files.grouplens.org/datasets/movielens/ml-latest.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540140b9-fce0-4709-8f63-8730fc4bf05b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[SCHEMA_ALREADY_EXISTS] Cannot create schema `movies` because it already exists.\nChoose a different name, drop the existing schema, or add the IF NOT EXISTS clause to tolerate pre-existing schema.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate database movies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[38;5;241m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [SCHEMA_ALREADY_EXISTS] Cannot create schema `movies` because it already exists.\nChoose a different name, drop the existing schema, or add the IF NOT EXISTS clause to tolerate pre-existing schema."
     ]
    }
   ],
   "source": [
    "spark.sql('create database movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "883e9023-112b-4589-b628-f2da46a1b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|   movies|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b892e36-9b60-43a0-93e3-c351f9d34efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('use movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f562095f-d186-4d8b-921f-0ae41bd3fd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('create table IF NOT EXISTS movies \\\n",
    "         (movieId int,title string,genres string) \\\n",
    "         row format delimited fields terminated by \",\"\\\n",
    "         stored as textfile')                                              # in textfile format\n",
    "spark.sql(\"create table IF NOT EXISTS ratings\\\n",
    "           (userId int,movieId int,rating float,timestamp string)\\\n",
    "           stored as ORC\" )                                                # in ORC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "452c12bb-ace4-4b85-b08b-249cf855a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   movies|   movies|      false|\n",
      "|   movies|  ratings|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9189cab4-faa6-4c9c-9886-c93f3f7f7ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/28 23:56:40 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table IF NOT EXISTS genres_by_count\\\n",
    "           (genres string,count int)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4a44c9c-b7fe-4567-8f1a-e3425d1dce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+-----------+\n",
      "|namespace|      tableName|isTemporary|\n",
      "+---------+---------------+-----------+\n",
      "|   movies|genres_by_count|      false|\n",
      "|   movies|         movies|      false|\n",
      "|   movies|        ratings|      false|\n",
      "+---------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b916c244-9d95-4a3c-8ada-7d145b0aef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                          |comment|\n",
      "+----------------------------+---------------------------------------------------+-------+\n",
      "|userId                      |int                                                |null   |\n",
      "|movieId                     |int                                                |null   |\n",
      "|rating                      |float                                              |null   |\n",
      "|timestamp                   |string                                             |null   |\n",
      "|                            |                                                   |       |\n",
      "|# Detailed Table Information|                                                   |       |\n",
      "|Catalog                     |spark_catalog                                      |       |\n",
      "|Database                    |movies                                             |       |\n",
      "|Table                       |ratings                                            |       |\n",
      "|Owner                       |jupyter                                            |       |\n",
      "|Created Time                |Wed Feb 28 23:56:36 GMT 2024                       |       |\n",
      "|Last Access                 |UNKNOWN                                            |       |\n",
      "|Created By                  |Spark 3.4.2                                        |       |\n",
      "|Type                        |MANAGED                                            |       |\n",
      "|Provider                    |hive                                               |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1709164596]                 |       |\n",
      "|Location                    |hdfs://master/user/hive/warehouse/movies.db/ratings|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.orc.OrcSerde          |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.orc.OrcInputFormat    |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat   |       |\n",
      "+----------------------------+---------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted ratings\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "071fc991-f871-4ea9-8670-1324b3715e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"load data local inpath './ml-latest/movies.csv'\\\n",
    "                 overwrite into table movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06fa1012-3acb-444f-ae68-6dd748fa3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "             StructField('userId', IntegerType()),\n",
    "             StructField('movieId', IntegerType()),\n",
    "             StructField('rating', DoubleType()),\n",
    "             StructField('timestamp', StringType())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49771cd7-129b-444f-ba38-f17f84b8493a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "038d51d4-7999-41df-9513-486978c7e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.csv(\"/user/jupyter/data/ratings.csv\", schema = schema, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "656174a2-3a37-4d12-a463-d18ec4a041e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de6e80e4-6372-4bca-8f41-44d856d64300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      1|   4.0|1225734739|\n",
      "|     1|    110|   4.0|1225865086|\n",
      "|     1|    158|   4.0|1225733503|\n",
      "|     1|    260|   4.5|1225735204|\n",
      "|     1|    356|   5.0|1225735119|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bdc28b6-c95d-48fa-883e-12e06792c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.createOrReplaceTempView(\"ratings_df_table\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e530f1c-e745-4944-bc06-cb029f0e157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into table ratings select * from ratings_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24bfeb16-40fc-4963-bf56-8cb5dffe25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|movieId|title                             |genres                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|null   |title                             |genres                                     |\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |\n",
      "|6      |Heat (1995)                       |Action|Crime|Thriller                      |\n",
      "|7      |Sabrina (1995)                    |Comedy|Romance                             |\n",
      "|8      |Tom and Huck (1995)               |Adventure|Children                         |\n",
      "|9      |Sudden Death (1995)               |Action                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from movies limit 10\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e36a917-dd0a-46ec-b1d7-cd2655508ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|timestamp |\n",
      "+------+-------+------+----------+\n",
      "|48744 |54503  |3.5   |1477820783|\n",
      "|48744 |54995  |4.0   |1478372524|\n",
      "|48744 |57669  |4.0   |1477820784|\n",
      "|48744 |60126  |3.0   |1478372854|\n",
      "|48744 |60756  |2.5   |1478450823|\n",
      "|48744 |61024  |3.5   |1478372866|\n",
      "|48744 |61132  |4.0   |1478372465|\n",
      "|48744 |63189  |3.0   |1478371836|\n",
      "|48744 |68952  |4.0   |1478373478|\n",
      "|48744 |69945  |0.5   |1478450809|\n",
      "+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from ratings limit 10\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da5d51cf-a81e-45eb-875e-e1176bd8e447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              genres|count|\n",
      "+--------------------+-----+\n",
      "|               Drama|10902|\n",
      "|         Documentary| 7493|\n",
      "|              Comedy| 6988|\n",
      "|  (no genres listed)| 6843|\n",
      "|        Comedy|Drama| 2855|\n",
      "|       Drama|Romance| 2504|\n",
      "|              Horror| 2318|\n",
      "|      Comedy|Romance| 1976|\n",
      "|            Thriller| 1318|\n",
      "|Comedy|Drama|Romance| 1158|\n",
      "|     Horror|Thriller| 1138|\n",
      "|      Drama|Thriller| 1133|\n",
      "|           Animation| 1085|\n",
      "|         Crime|Drama| 1031|\n",
      "|              Action|  745|\n",
      "|           Drama|War|  698|\n",
      "|        Action|Drama|  654|\n",
      "|             Western|  608|\n",
      "|             Romance|  587|\n",
      "|Crime|Drama|Thriller|  581|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select genres, count(*) as count from movies\\\n",
    "          group by genres\\\n",
    "          having count(*) > 500 \\\n",
    "          order by count desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "618a2d0f-dfae-4348-aa61-00f80f1570f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into table genres_by_count \\\n",
    "          select genres, count(*) as count from movies\\\n",
    "          group by genres\\\n",
    "          having count(*) >= 500 \\\n",
    "          order by count desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dce82719-4409-44ce-af7d-e1eb4150a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|     genres|count|\n",
      "+-----------+-----+\n",
      "|      Drama|10902|\n",
      "|Documentary| 7493|\n",
      "|     Comedy| 6988|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from genres_by_count order by count desc limit 3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4e6a664-49c7-4da6-9dd3-240f956abde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "             StructField('userId', IntegerType()),\n",
    "             StructField('movieId', IntegerType()),\n",
    "             StructField('tag', StringType()),\n",
    "             StructField('timestamp', StringType())\n",
    "            ])\n",
    "\n",
    "tags_df = spark.read.csv(\"/user/jupyter/data/tags.csv\", schema = schema, header = True)\n",
    "tags_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbf80005-a101-4d45-a983-5c96c88ab184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tags_df.registerTempTable('tags_df_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "320d960f-bf58-41e5-928f-754fa05ef044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+\n",
      "|namespace|       tableName|isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|   movies| genres_by_count|      false|\n",
      "|   movies|          movies|      false|\n",
      "|   movies|         ratings|      false|\n",
      "|         |ratings_df_table|       true|\n",
      "|         |   tags_df_table|       true|\n",
      "+---------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "897476ec-caa1-412c-9c21-6664cdbe2123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = spark.sql(\"select m.title, m.genres, r.movieId, r.userId,  r.rating, r.timestamp as ratingTimestamp, \\\n",
    "               t.tag, t.timestamp as tagTimestamp from ratings as r inner join tags_df_table as t\\\n",
    "               on r.movieId = t.movieId and r.userId = t.userId inner join movies as m on r.movieId = m.movieId\")\n",
    "type(joined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56a66c67-5b25-48a4-9ee2-8f97ef7d7d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------------------------+------+\n",
      "|title           |genres                                     |rating|\n",
      "+----------------+-------------------------------------------+------+\n",
      "|Toy Story (1995)|Adventure|Animation|Children|Comedy|Fantasy|4.0   |\n",
      "|Toy Story (1995)|Adventure|Animation|Children|Comedy|Fantasy|4.0   |\n",
      "|Toy Story (1995)|Adventure|Animation|Children|Comedy|Fantasy|4.0   |\n",
      "|Toy Story (1995)|Adventure|Animation|Children|Comedy|Fantasy|4.0   |\n",
      "|Toy Story (1995)|Adventure|Animation|Children|Comedy|Fantasy|4.0   |\n",
      "+----------------+-------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined.select(['title','genres','rating']).show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ad292ef-a9f3-4790-b5aa-33ad32a829ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
